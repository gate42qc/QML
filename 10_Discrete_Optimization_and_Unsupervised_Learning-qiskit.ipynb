{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Unsupervised learning means a lack of labels: we are looking for structure in the data, without having an *a priori* intuition what that structure might be. A great example is clustering, where the goal is to identify instances that clump together in some high-dimensional space. Unsupervised learning in general is a harder problem. Deep learning revolutionized supervised learning and it had made significant advances in unsupervised learning, but there remains plenty of room for improvement. In this notebook, we look at how we can map an unsupervised learning problem to graph optimization, which in turn we can solve on a quantum computer.\n",
                "\n",
                "# Mapping clustering to discrete optimization\n",
                "\n",
                "Assume that we have some points $\\{x_i\\}_{i=1}^N$ lying in some high-dimensional space $\\mathbb{R}^d$. How do we tell which ones are close to one another and which ones are distant? To get some intuition, let's generate a simple dataset with two distinct classes. The first five instances will belong to class 1, and the second five to class 2:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2018-11-19T20:10:21.386145Z",
                    "start_time": "2018-11-19T20:10:20.886249Z"
                }
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from mpl_toolkits.mplot3d import Axes3D\n",
                "%matplotlib inline\n",
                "\n",
                "n_instances = 10\n",
                "class_1 = np.random.rand(n_instances\/\/2, 3)\/5\n",
                "class_2 = (0.6, 0.1, 0.05) + np.random.rand(n_instances\/\/2, 3)\/5\n",
                "data = np.concatenate((class_1, class_2))\n",
                "colors = [\"red\"] * (n_instances\/\/2) + [\"green\"] * (n_instances\/\/2)\n",
                "fig = plt.figure()\n",
                "ax = fig.add_subplot(111, projection='3d', xticks=[], yticks=[], zticks=[])\n",
                "ax.scatter(data[:, 0], data[:, 1], data[:, 2], c=colors);"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The high-dimensional space is endowed with some measure of distance, the Euclidean distance being the simplest case. We can calculate all pairwise distances between the data points:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2018-11-19T20:10:21.407379Z",
                    "start_time": "2018-11-19T20:10:21.393951Z"
                }
            },
            "outputs": [],
            "source": [
                "import itertools\n",
                "w = np.zeros((n_instances, n_instances))\n",
                "for i, j in itertools.product(*[range(n_instances)]*2):\n",
                "    w[i, j] = np.linalg.norm(data[i]-data[j])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This matrix is sometimes called the Gram or the kernel matrix. The Gram matrix contains a fair bit of information about the topology of the points in the high-dimensional space, but it is not easy to see. We can think of the Gram matrix as the weighted adjacency matrix of a graph: two nodes represent two data instances. Their distance as contained in the Gram matrix is the weight on the edge that connects them. If the distance is zero, they are not connected by an edge. In general, this is a dense graph with many edges -- sparsity can be improved by a distance function that gets exponentially smaller.\n",
                "\n",
                "What can we do with this graph to find the clusters? We could look for the max-cut, that is, the collection of edges that would split the graph in exactly two if removed, while maximizing the total weight of these edges [[1](#1)]. This is a well-known NP-hard problem, but it also very naturally maps to an Ising model.\n",
                "\n",
                "The spin variables $\\sigma_i \\in \\{-1, +1\\}$ take on value $\\sigma_i = +1$ if a data instance is in cluster 1 (nodes $V_1$ in the graph), and $\\sigma_i = -1$ if the data instance is in cluster 2 (nodes $V_2$ in the graph). The cost of a cut is\n",
                "\n",
                "$$\n",
                "\\sum_{i\\in V_1, j\\in V_2} w_{ij}\n",
                "$$\n",
                "\n",
                "Let us assume a fully connected graph. Then, accounting for the symmetry of the adjacency matrix, we can expand this as\n",
                "$$\n",
                "\\frac{1}{4}\\sum_{i, j} w_{ij} - \\frac{1}{4} \\sum_{i, j} w_{ij} \\sigma_i \\sigma_j\n",
                "$$\n",
                "$$\n",
                "= \\frac{1}{4}\\sum_{i, j\\in V} w_{ij} (1- \\sigma_i \\sigma_j).\n",
                "$$                 \n",
                "\n",
                "By taking the negative of this, we can directly solve the problem by a quantum optimizer."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Solving the max-cut problem by QAOA\n",
                "\n",
                "Most quantum computing frameworks have convenience functions defined for common graph optimization algorithms, and max-cut is a staple. This reduces our task to importing the relevant functions:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2018-11-19T20:10:23.147272Z",
                    "start_time": "2018-11-19T20:10:21.412811Z"
                }
            },
            "outputs": [],
            "source": [
                "from qiskit_aqua import get_aer_backend, QuantumInstance\n",
                "from qiskit_aqua.algorithms import QAOA\n",
                "from qiskit_aqua.components.optimizers import COBYLA\n",
                "from qiskit_aqua.translators.ising import maxcut"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Setting $p=1$ in the QAOA algorithm, we can initialize it with the max-cut problem."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2018-11-19T20:10:28.190764Z",
                    "start_time": "2018-11-19T20:10:23.152849Z"
                }
            },
            "outputs": [],
            "source": [
                "qubit_operators, offset = maxcut.get_maxcut_qubitops(w)\n",
                "p = 1\n",
                "optimizer = COBYLA()\n",
                "qaoa = QAOA(qubit_operators, optimizer, p, operator_mode='matrix')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here the choice of the classical optimizer `COBYLA` was arbitrary. Let us run this and analyze the solution. This can take a while on a classical simulator."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2018-11-19T20:12:33.139743Z",
                    "start_time": "2018-11-19T20:10:28.202147Z"
                }
            },
            "outputs": [],
            "source": [
                "backend = get_aer_backend('statevector_simulator')\n",
                "quantum_instance = QuantumInstance(backend, shots=100)\n",
                "result = qaoa.run(quantum_instance)\n",
                "x = maxcut.sample_most_likely(result['eigvecs'][0])\n",
                "graph_solution = maxcut.get_graph_solution(x)\n",
                "print('energy:', result['energy'])\n",
                "print('maxcut objective:', result['energy'] + offset)\n",
                "print('solution:', maxcut.get_graph_solution(x))\n",
                "print('solution objective:', maxcut.maxcut_value(x, w))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Looking at the solution, the cut matches the clustering structure."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Solving the max-cut problem by annealing\n",
                "\n",
                "Naturally, the same problem can be solved on an annealer. Our only task is to translate the couplings and the on-site fields to match the programming interface:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2018-11-19T20:12:37.587621Z",
                    "start_time": "2018-11-19T20:12:36.386739Z"
                }
            },
            "outputs": [],
            "source": [
                "import dimod\n",
                "\n",
                "J, h = {}, {}\n",
                "for i in range(n_instances):\n",
                "    h[i] = 0\n",
                "    for j in range(i+1, n_instances):\n",
                "        J[(i, j)] = w[i, j]\n",
                "\n",
                "model = dimod.BinaryQuadraticModel(h, J, 0.0, dimod.SPIN)\n",
                "sampler = dimod.SimulatedAnnealingSampler()\n",
                "response = sampler.sample(model, num_reads=10)\n",
                "print(\"Energy of samples:\")\n",
                "for solution in response.data():\n",
                "    print(\"Energy:\", solution.energy, \"Sample:\", solution.sample)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you look at the first sample, you will see that the first five data instances belong to the same graph partition, matching the actual cluster."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# References\n",
                "\n",
                "[1] Otterbach, J. S., Manenti, R., Alidoust, N., Bestwick, A., Block, M., Bloom, B., Caldwell, S., Didier, N., Fried, E. Schuyler, Hong, S., Karalekas, P., Osborn, C. B., Papageorge, A., Peterson, E. C., Prawiroatmodjo, G., Rubin, N., Ryan, Colm A., Scarabelli, D., Scheer, M., Sete, E. A., Sivarajah, P., Smith, Robert S., Staley, A., Tezak, N., Zeng, W. J., Hudson, A., Johnson, Blake R., Reagor, M., Silva, M. P. da, Rigetti, C. (2017). [Unsupervised Machine Learning on a Hybrid Quantum Computer](https:\/\/arxiv.org\/abs\/1712.05771). *arXiv:1712.05771*. <a id='1'><\/a>"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}